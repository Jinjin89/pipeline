configfile: "config.yaml"
#############################################
# Functions
# 1) Using pandas to read samples metadata
#############################################

import pandas as pd
import os

class pe_sample:
    def __init__(self,input_sample_meta_file,sample_column = "sample",R1_column = "R1",R2_column = "R2",output_dir = "results"):        # the input params
        self.sample_meta_file = input_sample_meta_file
        self.sample_column = sample_column
        self.R1_column = R1_column
        self.R2_column = R2_column
        # the output params
        self.output_dir = output_dir
        print("="*50)
        if not os.path.isdir(self.output_dir):
            print("output direcory not found, create it!")
            print(self.output_dir)
            os.mkdir(self.output_dir)
        else:
            print("output direcory found, skip!")

    def read_sample_file(self):
        if self.sample_meta_file.endswith("csv"):
            self.samples_df = pd.read_csv(self.sample_meta_file)
        elif self.sample_meta_file.endswith("txt") or self.sample_meta_file.endswith("tsv"):
            self.samples_df = pd.read_table(self.sample_meta_file,sep = "\s+")
        else:
            print("please supply sample metadata with csv/txt/tsv format!")
            exit("###############################\nThere is something wrong, you know, I only accept the files with csv/txt/tsv extension!\n###############################")

        # 1) get all the samples
        self.all_samples = self.samples_df[self.sample_column].unique().tolist()
        # 3) set index
        self.samples_df["index"] = self.samples_df[self.sample_column]
        self.samples_df.set_index("index",inplace=True)

    def R1(self,wildcards):
        return self.samples_df.at[wildcards.sample,"R1"]

    def R2(self,wildcards):
        return self.samples_df.at[wildcards.sample,"R2"]
    
    def outputMetadata(self):
        print("="*50)
        output_meta_file = path_generator([self.output_dir,"meta.csv"])
        if os.path.isfile(output_meta_file):
            print("meta data found ,skip! please check the meta data\nis consistent with input_file, or you could delete\nit and rerun snakemake with snakemake -np")
        else:
            print("meta data not found, create it with input_file")
            # 1) clean reads postion
            self.samples_df["R1_qc"] = [path_generator([self.output_dir,str(x),"step01_qc",str(x)+".trim.R1.fq.gz"]) for x in self.samples_df[self.sample_column]]
            self.samples_df["R2_qc"] = [path_generator([self.output_dir,str(x),"step01_qc",str(x)+".trim.R2.fq.gz"]) for x in self.samples_df[self.sample_column]]
            # 2) aligned bam postion
            self.samples_df["bam"] = [path_generator([self.output_dir,str(x),"step02_align",str(x)+".Aligned.sortedByCoord.out.bam"]) for x in self.samples_df[self.sample_column]]
            self.samples_df["counts"] = [path_generator([self.output_dir,str(x),"step02_align",str(x)+".ReadsPerGene.out.tab"]) for x in self.samples_df[self.sample_column]]
            # 3) expression file position
            self.samples_df["gene_expression"] = [path_generator([self.output_dir,str(x),"step03_gene_abundance",str(x)+"_expression.txt"]) for x in self.samples_df[self.sample_column]]
            print("meta data shape:(should have same rows with input_file)")
            print(self.samples_df.shape)
            self.samples_df.to_csv(output_meta_file,index=None)

def path_generator(input_list):
    return "/".join(input_list)

#############################################
# load configs
#############################################

samples_info = pe_sample(config["input_file"],output_dir = config["output_directory"])

# 1) get samples
samples_info.read_sample_file()
samples_info.outputMetadata()

# create dir
samples = samples_info.all_samples
# print(samples_info.samples_df)
print("="*50)
print("How many samples input?")
print(len(samples))
print("============>end of data preparations<============")
print("="*50)
#############################################
# Rules
#############################################

rule all:
    input:
        # 1) get clean data
        # expand(path_generator([config["output_directory"],"{sample}","step01_qc","{sample}.html"]),sample = samples)
        # 2) get align data 
        #expand(path_generator([config["output_directory"],"{sample}","step02_align","{sample}.Aligned.sortedByCoord.out.bam.bai"]),sample = samples)
        # 3) stringtie -> gene expression
        #expand(path_generator([config["output_directory"],"{sample}","step03_gene_abundance","{sample}_expression.txt"]),sample = samples)
        #expand(path_generator([config["output_directory"],"{sample}","step04_gene_fusion","star-fusion.fusion_predictions.tsv"]),sample = samples)
        #path_generator([config["output_directory"],'done','mRNA.done']),
        path_generator([config["output_directory"],'done','starFusion.done'])
rule fastp:
    input:
        fq1 = samples_info.R1,
        fq2 = samples_info.R2
    output:
        fq1 =  path_generator([config["output_directory"],"{sample}","step01_qc","{sample}.trim.R1.fq.gz"]),
        fq2 = path_generator([config["output_directory"],"{sample}","step01_qc","{sample}.trim.R2.fq.gz"]),
        html = path_generator([config["output_directory"],"{sample}","step01_qc","{sample}.html"]),
        json = path_generator([config["output_directory"],"{sample}","step01_qc","{sample}.json"]),
        log = path_generator([config["output_directory"],"{sample}","step01_qc","{sample}.log"]) 

    threads: config["fastp_threads"],
    params:
        dir = path_generator([config["output_directory"],"{sample}","step01_qc"]),
        tool=config["fastp"],
        reads_to_process=config["reads_to_process"]
    shell:
        '''
        [[ ! -d {params.dir} ]] && mkdir -p {params.dir}

        {params.tool}\
        -i {input.fq1} -I {input.fq2} -o {output.fq1} -O {output.fq2}\
        -w {threads}\
        --detect_adapter_for_pe \
        -c\
        -n 6\
        -q 20\
        -u 40\
        -h {output.html} \
        --reads_to_process {params.reads_to_process}\
        -j {output.json} >{output.log}
        '''

rule star1pass:
    input:
        fq1 = path_generator([config["output_directory"],"{sample}","step01_qc","{sample}.trim.R1.fq.gz"]),
        fq2 = path_generator([config["output_directory"],"{sample}","step01_qc","{sample}.trim.R2.fq.gz"])

    output:
        sj_out_tab = path_generator([config["output_directory"],"{sample}","step02_align","{sample}.SJ.out.tab"])
        # sj_out_tab = samples_info.output_sj_dir + "{sample}.SJ.out.tab"
    threads:  config["star_threads"]
    params:
        tool= config["star"],
        ref = config["ref"],
        dir = path_generator([config["output_directory"],"{sample}","step02_align"]),
        prefix = path_generator([config["output_directory"],"{sample}","step02_align","{sample}."])
    shell:
        """
        [[ ! -d {params.dir} ]] && mkdir -p {params.dir}
        {params.tool}\
        --genomeDir {params.ref}\
        --readFilesIn {input.fq1} {input.fq2}\
        --outFileNamePrefix {params.prefix}\
        --runThreadN {threads} \
        --outFilterMultimapScoreRange 1 \
        --outFilterMultimapNmax 20\
        --outFilterMismatchNmax 10\
        --alignIntronMax 500000\
        --alignMatesGapMax 1000000\
        --sjdbScore 2\
        --alignSJDBoverhangMin 1\
        --genomeLoad NoSharedMemory\
        --readFilesCommand zcat\
        --outFilterMatchNminOverLread 0.33\
        --outFilterScoreMinOverLread 0.33\
        --sjdbOverhang 100\
        --outSAMstrandField intronMotif\
        --outSAMtype None\
        --outSAMmode None
        """

rule star2pass:
    input:
        fq1 = path_generator([config["output_directory"],"{sample}","step01_qc","{sample}.trim.R1.fq.gz"]),
        fq2 = path_generator([config["output_directory"],"{sample}","step01_qc","{sample}.trim.R2.fq.gz"]),
        sj  = path_generator([config["output_directory"],"{sample}","step02_align","{sample}.SJ.out.tab"])

    output:
        bam = path_generator([config["output_directory"],"{sample}","step02_align","{sample}.Aligned.sortedByCoord.out.bam"])
    threads: config["star_threads"]
    params:
        tool=config["star"],
        prefix = path_generator([config["output_directory"],"{sample}","step02_align","{sample}."]),
        ref = config["ref"],
        RG=r"ID:NextSEQ\tSM:{sample}\tPL:Illumina\tLB:TRs"
    shell:
        """
        {params.tool}\
        --genomeDir {params.ref}\
        --readFilesIn {input.fq1} {input.fq2}\
        --outFileNamePrefix {params.prefix}\
        --sjdbFileChrStartEnd {input.sj}\
        --runThreadN {threads}\
        --outFilterMultimapScoreRange 1\
        --outFilterMultimapNmax 20\
        --outFilterMismatchNmax 10\
        --alignIntronMax 500000\
        --alignMatesGapMax 1000000\
        --sjdbScore 2\
        --alignSJDBoverhangMin 1\
        --genomeLoad NoSharedMemory\
        --limitBAMsortRAM 0\
        --readFilesCommand zcat\
        --outFilterMatchNminOverLread 0.33\
        --outFilterScoreMinOverLread 0.33\
        --sjdbOverhang 100\
        --outSAMstrandField intronMotif\
        --outSAMattributes NH HI NM MD AS XS\
        --outSAMunmapped Within\
        --outSAMtype BAM SortedByCoordinate\
        --outSAMheaderHD @HD VN:1.4\
        --outSAMattrRGline {params.RG}\
        --quantMode GeneCounts
        """

rule bamIndex:
    input: 
        bam = path_generator([config["output_directory"],"{sample}","step02_align","{sample}.Aligned.sortedByCoord.out.bam"])
    output: 
        bai = path_generator([config["output_directory"],"{sample}","step02_align","{sample}.Aligned.sortedByCoord.out.bam.bai"])
    threads: config["samtools_threads"]
    params:
        tool=config["samtools"]
    shell:
        '''
        {params.tool} index  -@ {threads} {input.bam}
        '''

rule stringtie:
    input: 
        bam = path_generator([config["output_directory"],"{sample}","step02_align","{sample}.Aligned.sortedByCoord.out.bam"])
    output: 
        gtf = path_generator([config["output_directory"],"{sample}","step03_gene_abundance","{sample}_gene.gtf"]),
        expression = path_generator([config["output_directory"],"{sample}","step03_gene_abundance","{sample}_expression.txt"])
    threads: config["stringtie_threads"]
    params:
        tool = config["stringtie"],
        gtf = config["gtf"],
        dir = path_generator([config["output_directory"],"{sample}","step03_gene_abundance"])
    shell:
        '''
        [[ ! -d {params.dir} ]] && mkdir -p {params.dir}
        {params.tool}\
            {input.bam}\
            -G {params.gtf}\
            -p {threads}\
            -o {output.gtf}\
            -A {output.expression}\
            -e
        '''

rule starFusion:
    input:
        fq1 = path_generator([config["output_directory"],"{sample}","step01_qc","{sample}.trim.R1.fq.gz"]),
        fq2 = path_generator([config["output_directory"],"{sample}","step01_qc","{sample}.trim.R2.fq.gz"])
    output: 
        starFusion = path_generator([config["output_directory"],"{sample}","step04_gene_fusion","star-fusion.fusion_predictions.tsv"])
    threads: config["starFusion_threads"]
    params:
        ctat_genome_lib_build_dir = config['ctat_genome_lib_build_dir'],
        STAR_PATH = config['starFusion_star'],
        tool = config["starFusion"],
        dir = path_generator([config["output_directory"],"{sample}","step04_gene_fusion"])
    shell:
        '''
        {params.tool}\
            --left_fq {input.fq1} \
            --right_fq {input.fq2} \
            --genome_lib_dir {params.ctat_genome_lib_build_dir}\
            -O {params.dir}\
            --CPU {threads}\
            --STAR_PATH {params.STAR_PATH}
        '''

# done file

rule mRNADoneFile:
    input:expand(path_generator([config["output_directory"],"{sample}","step03_gene_abundance","{sample}_expression.txt"]),sample = samples)
    output: path_generator([config["output_directory"],'done','mRNA.done'])
    params: path_generator([config["output_directory"],'done'])
    shell: 
        '''
        [[ ! -d {params} ]] && mkdir -p {params}
        touch {output}

        '''


rule starFusionDoneFile:
    input:expand(path_generator([config["output_directory"],"{sample}","step03_gene_abundance","{sample}_expression.txt"]),sample = samples)
    output: path_generator([config["output_directory"],'done','starFusion.done'])
    params: path_generator([config["output_directory"],'done'])
    shell: 
        '''
        [[ ! -d {params} ]] && mkdir -p {params}
        touch {output}

        '''